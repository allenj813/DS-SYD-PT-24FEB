{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QaGbHIhQLFYq"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sMx6dqz7LFYv"
   },
   "source": [
    "# Lab 2.2.4 \n",
    "# *The Google BigQuery UI and API*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SKGiPVSwLFYx"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aKMV45iQLFY2"
   },
   "source": [
    "The Google BigQuery UI provides access to Google's extensive collection of public data sets via an SQL-based query engine. \n",
    "\n",
    "The BigQuery API provides programmatic access to the data sets.\n",
    "\n",
    "We can use the UI to discover interesting data before writing Python code to access it. Then we can reproduce it in an API request so as to aggregate large amounts of data on Google's infrastructure before pulling the results into our application.\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q3JonnfULFY6"
   },
   "source": [
    "## BigQuery Web UI\n",
    "\n",
    "Work through the Quickstart at https://cloud.google.com/bigquery/docs/quickstarts/quickstart-web-ui.\n",
    "\n",
    "You will need to set up a Google Cloud Platform account if you don't already have one. (This should not cost anything during the trial period unless you perform a large amount of querying. Afterwards, costs are based on actual resource usage, but most offerings have a free tier.)\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QM5QOIBpLFY9"
   },
   "source": [
    "## BigQuery API\n",
    "\n",
    "You should already have the Google Cloud Client Library for Python installed (https://cloud.google.com/python/setup).\n",
    "\n",
    "- Open Google Cloud Console (https://console.cloud.google.com/home/) and select to create a project.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "- Under \"Getting Started\", select \"Enable APIs and get credentials such as keys\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Ni9g5D7LFY_"
   },
   "source": [
    "- In the API table, make sure the BigQuery API is enabled. Page back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FYjui9nrLFZC"
   },
   "source": [
    "### Authentication\n",
    "\n",
    "Go to https://cloud.google.com/docs/authentication/production and click the button to create a service account.\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OYryTo8SLFZE"
   },
   "source": [
    "- Fill out the form, giving the account an appropriate name, and choose \"Project Owner\" for Account Type.\n",
    "\n",
    "- Click \"Create\".\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lUx6uvpALFZF"
   },
   "source": [
    "- The keys will get saved to your computer:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "- Note the location and copy the file path (of the json file) to somewhere safe, for future reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I1MMIwTULFZH"
   },
   "source": [
    "- You should then see a screen like this:\n",
    "\n",
    "![image.png](attachment:image.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DnYr6eJ-LFZH"
   },
   "source": [
    "- See here for more information:\n",
    "\n",
    "https://cloud.google.com/iam/docs/understanding-service-accounts?&_ga=2.173177830.-495703703.1532572448#managing_service_account_keys "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pQKOrjk8LFZI"
   },
   "source": [
    "This is supposed to get implicit key retrieval working:\n",
    "\n",
    "- Windows:\n",
    "    `set GOOGLE_APPLICATION_CREDENTIALS=[PATH]`\n",
    "    \n",
    "- Linux, MacOS:\n",
    "    `export GOOGLE_APPLICATION_CREDENTIALS=[PATH]`\n",
    "    \n",
    "where `[PATH]` is the full file path of your json key file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5pvHgwVcLFZJ"
   },
   "source": [
    "### Using the Python API\n",
    "\n",
    "Google provides Python libraries for wrapping the Google APIs. For conda users, these are available on the \"conda-forge\" channel. (There are other Python libraries for Google APIs, possibly adding novel features or ease of use, but Google's is presumably the most current.)\n",
    "\n",
    "(Installing the \"google-cloud-storage\" and \"google-cloud-bigquery\" libraries should cover all the dependences for this lab.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0o5eABcXLFZL"
   },
   "outputs": [],
   "source": [
    "# Importing libraries from google.cloud\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.bigquery import Dataset\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "olVeVnL_LFZO"
   },
   "source": [
    "If you have managed to get implicit key retrieval working, you can call `.Client()` with no argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]='/Users/allenj/Documents/Keys/Explorations-83ac1354c16d.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qR2cXGt4LFZP"
   },
   "outputs": [],
   "source": [
    "storage_client = storage.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hHZQSxxqLFZR"
   },
   "source": [
    "If you aren't so lucky, you need to invoke a method of the `.Client` object that takes the path to your key files as a string argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8nTBh0TvLFZR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/allenj/Documents/Keys/Explorations-83ac1354c16d.json'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_path = '[PATH]'  # put the path to your json key file here \n",
    "#,                    (or write code to load it from a file that your notebook can easily find)\n",
    "key_path = '/Users/allenj/Documents/Keys/Explorations-83ac1354c16d.json'\n",
    "key_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0XKIHVy8LFZT"
   },
   "source": [
    "This should not throw an error if key retrieval / assignemnt worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gfqDJPU9LFZT"
   },
   "outputs": [],
   "source": [
    "# For storage\n",
    "storage_client = storage.Client.from_service_account_json(key_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z1sntjgJLFZU"
   },
   "source": [
    "*Nb. The `storage` object was used in the above example, but there are other objects of interest that have polymorphic `Client` members that are used similarly, such as `bigquery`, which is used below.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UBEZd1KiLFZV"
   },
   "source": [
    "If implicit key retrieval is working for you, execute this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QL7DoAX7LFZV"
   },
   "outputs": [],
   "source": [
    "# Connection to big query\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zSA3wp7NLFZX"
   },
   "source": [
    "if not, execute this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ljcqTlxXLFZX"
   },
   "outputs": [],
   "source": [
    "client = bigquery.Client.from_service_account_json(key_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kS1b8GXYLFZY"
   },
   "source": [
    "This client is associated with the default project (which was set or defaulted in the BigQuery UI): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LflN4IlzLFZY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'explorations-275222'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BXQNVF1XLFZb"
   },
   "source": [
    "A BigQuery project contains datasets. Datasets contain tables. To get at the data in a table we need to create a reference that covers this hierarchy; in the `bigquery` library this looks like `project.dataset.table`.  \n",
    "\n",
    "(Nb. Queries can be performed on prjects and datasets, but most queries are performed on tables.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fOtLSyBdLFZb"
   },
   "source": [
    "To explore the public datasets we will start by reassgining our `client` variable using optional `project` parameter (set to `bigquery-public-data`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SQTQ24whLFZc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigquery-public-data\n"
     ]
    }
   ],
   "source": [
    "#project = 'bigquery-public-data'\n",
    "client = bigquery.Client.from_service_account_json(key_path, project = 'bigquery-public-data')\n",
    "print(client.project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZonWy10xLFZe"
   },
   "source": [
    "Here is how to get a list of the datasets in the current project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'google.cloud.bigquery.client.Client'>\n"
     ]
    }
   ],
   "source": [
    "print(type(client))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yQan0v1vLFZe",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<google.cloud.bigquery.dataset.DatasetListItem object at 0x11d1640d0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d164910>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d10a2d0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d10aa10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d10af50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d10a150>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d16d9d0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d16da50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d06d6d0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d171f50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d171fd0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d171810>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d0f3450>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d0f3c10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174050>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174bd0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174b90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174dd0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174b10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174a90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174950>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d1749d0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174d90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174d50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174a50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174c10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174ad0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d1747d0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174b50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174750>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174810>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174790>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174c90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174c50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181490>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d1814d0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181510>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181550>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181590>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d1815d0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181610>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181650>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181690>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d1816d0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181710>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181750>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181790>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d1817d0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181810>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181850>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d08eed0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d1642d0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d164e90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d164310>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d164ed0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181910>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181b50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181b10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181ad0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181a90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181dd0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181f10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181ed0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181e90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181e50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181c90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181a10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d1823d0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d182350>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d1822d0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d182290>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d182250>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d182190>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d182210>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d1746d0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174690>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174290>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174850>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d1744d0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174510>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d1743d0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174550>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174350>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174590>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174cd0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174650>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174450>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174390>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d174710>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d185a50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d185a90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d185ad0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d185b10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d185b50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d185b90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d185bd0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d185c10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d185c50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d185c90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d185cd0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d10a0d0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d185d90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d185e90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d185f90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d185f50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d185f10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181890>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d1819d0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181990>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d1818d0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181d50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181a50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181bd0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181f90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181c50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181fd0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181b90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181f50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181e10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d181d10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d189290>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d1893d0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d189390>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d189350>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d189310>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d189150>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d189850>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d1897d0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d189750>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d189710>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d1896d0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d189610>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d189690>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d1742d0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d1820d0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d182090>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d182110>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d1821d0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d182150>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x11d18c610>]\n"
     ]
    }
   ],
   "source": [
    "datasets = list(client.list_datasets())\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_UoYS4suLFZg"
   },
   "source": [
    "That wasn't helpful. We need to go deeper into the object structure to get at something meaningful. Actually, the `dataset_id` member contains the name attribute of a `dataset` object; write some code to print that name for each member of the list that was created above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-c7f797224aab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatasets_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'datasets_id' is not defined"
     ]
    }
   ],
   "source": [
    "datasets_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "austin_311\n",
      "austin_bikeshare\n",
      "austin_crime\n",
      "austin_incidents\n",
      "austin_waste\n",
      "baseball\n",
      "bitcoin_blockchain\n",
      "bls\n",
      "bls_qcew\n",
      "catalonian_mobile_coverage\n",
      "catalonian_mobile_coverage_eu\n",
      "census_bureau_acs\n",
      "census_bureau_construction\n",
      "census_bureau_international\n",
      "census_bureau_usa\n",
      "census_utility\n",
      "cfpb_complaints\n",
      "chicago_crime\n",
      "chicago_taxi_trips\n",
      "cloud_storage_geo_index\n",
      "cms_codes\n",
      "cms_medicare\n",
      "cms_synthetic_patient_data_omop\n",
      "covid19_ecdc\n",
      "covid19_google_mobility\n",
      "covid19_italy\n",
      "covid19_italy_eu\n",
      "covid19_jhu_csse\n",
      "covid19_jhu_csse_eu\n",
      "covid19_nyt\n",
      "covid19_usafacts\n",
      "crypto_bitcoin\n",
      "crypto_bitcoin_cash\n",
      "crypto_dash\n",
      "crypto_dogecoin\n",
      "crypto_ethereum\n",
      "crypto_ethereum_classic\n",
      "crypto_litecoin\n",
      "crypto_zcash\n",
      "eclipse_megamovie\n",
      "epa_historical_air_quality\n",
      "ethereum_blockchain\n",
      "faa\n",
      "fcc_political_ads\n",
      "fda_drug\n",
      "fda_food\n",
      "fdic_banks\n",
      "fec\n",
      "fhir_synthea\n",
      "genomics_cannabis\n",
      "genomics_rice\n",
      "geo_census_blockgroups\n",
      "geo_census_tracts\n",
      "geo_international_ports\n",
      "geo_openstreetmap\n",
      "geo_us_boundaries\n",
      "geo_us_census_places\n",
      "geo_us_roads\n",
      "geo_whos_on_first\n",
      "geolite2\n",
      "ghcn_d\n",
      "ghcn_m\n",
      "github_repos\n",
      "google_analytics_sample\n",
      "google_political_ads\n",
      "hacker_news\n",
      "human_genome_variants\n",
      "human_variant_annotation\n",
      "iowa_liquor_sales\n",
      "irs_990\n",
      "labeled_patents\n",
      "libraries_io\n",
      "london_bicycles\n",
      "london_crime\n",
      "london_fire_brigade\n",
      "medicare\n",
      "ml_datasets\n",
      "moon_phases\n",
      "nasa_wildfire\n",
      "ncaa_basketball\n",
      "new_york\n",
      "new_york_311\n",
      "new_york_citibike\n",
      "new_york_mv_collisions\n",
      "new_york_subway\n",
      "new_york_taxi_trips\n",
      "new_york_trees\n",
      "nhtsa_traffic_fatalities\n",
      "nlm_rxnorm\n",
      "noaa_goes16\n",
      "noaa_goes17\n",
      "noaa_gsod\n",
      "noaa_historic_severe_storms\n",
      "noaa_hurricanes\n",
      "noaa_icoads\n",
      "noaa_lightning\n",
      "noaa_passive_acoustic_index\n",
      "noaa_pifsc_metadata\n",
      "noaa_preliminary_severe_storms\n",
      "noaa_significant_earthquakes\n",
      "noaa_tsunami\n",
      "nppes\n",
      "open_images\n",
      "openaq\n",
      "persistent_udfs\n",
      "samples\n",
      "san_francisco\n",
      "san_francisco_311\n",
      "san_francisco_bikeshare\n",
      "san_francisco_film_locations\n",
      "san_francisco_sffd_service_calls\n",
      "san_francisco_sfpd_incidents\n",
      "san_francisco_transit_muni\n",
      "san_francisco_trees\n",
      "sdoh_bea_cainc30\n",
      "sdoh_cdc_wonder_natality\n",
      "sdoh_cms_dual_eligible_enrollment\n",
      "sdoh_hrsa_shortage_areas\n",
      "sdoh_hud_housing\n",
      "sdoh_hud_pit_homelessness\n",
      "sdoh_snap_enrollment\n",
      "sec_quarterly_financials\n",
      "stackoverflow\n",
      "sunroof_solar\n",
      "the_met\n",
      "umiami_lincs\n",
      "un_sdg\n",
      "usa_names\n",
      "usda_nass_agriculture\n",
      "usfs_fia\n",
      "utility_eu\n",
      "utility_us\n",
      "wikipedia\n",
      "wise_all_sky_data_release\n",
      "world_bank_global_population\n",
      "world_bank_health_population\n",
      "world_bank_intl_debt\n",
      "world_bank_intl_education\n",
      "world_bank_wdi\n",
      "worldpop\n"
     ]
    }
   ],
   "source": [
    "# Print each item in datasets using a loop\n",
    "# 'dataset_id' is part of the API parameter documentation\n",
    "for dataset in datasets:\n",
    "    print(dataset.dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1VKuobUSLFZk"
   },
   "source": [
    "The google API objects in the `bigquery` library have their own overloads of the format() function that make them easier to read. Below is a function that exploits the `format` method of `project` and `dataset_id`, providing an easy way to list datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "obqd0X0vLFZl"
   },
   "outputs": [],
   "source": [
    "# function for listing datasets in a project:\n",
    "def printDatasetList(client):\n",
    "    project = client.project    #: only one project can be associated with a client instance\n",
    "    datasets = list(client.list_datasets()) # function to get the list of datasets\n",
    "    if datasets:\n",
    "        print('Datasets in project {}:'.format(project))\n",
    "        for dataset in datasets:  \n",
    "            print('\\t{}'.format(dataset.dataset_id))\n",
    "        found = True\n",
    "    else:\n",
    "        print('{} project does not contain any datasets.'.format(project))\n",
    "        found = False\n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TcS8DXenLFZn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets in project bigquery-public-data:\n",
      "\taustin_311\n",
      "\taustin_bikeshare\n",
      "\taustin_crime\n",
      "\taustin_incidents\n",
      "\taustin_waste\n",
      "\tbaseball\n",
      "\tbitcoin_blockchain\n",
      "\tbls\n",
      "\tbls_qcew\n",
      "\tcatalonian_mobile_coverage\n",
      "\tcatalonian_mobile_coverage_eu\n",
      "\tcensus_bureau_acs\n",
      "\tcensus_bureau_construction\n",
      "\tcensus_bureau_international\n",
      "\tcensus_bureau_usa\n",
      "\tcensus_utility\n",
      "\tcfpb_complaints\n",
      "\tchicago_crime\n",
      "\tchicago_taxi_trips\n",
      "\tcloud_storage_geo_index\n",
      "\tcms_codes\n",
      "\tcms_medicare\n",
      "\tcms_synthetic_patient_data_omop\n",
      "\tcovid19_ecdc\n",
      "\tcovid19_google_mobility\n",
      "\tcovid19_italy\n",
      "\tcovid19_italy_eu\n",
      "\tcovid19_jhu_csse\n",
      "\tcovid19_jhu_csse_eu\n",
      "\tcovid19_nyt\n",
      "\tcovid19_usafacts\n",
      "\tcrypto_bitcoin\n",
      "\tcrypto_bitcoin_cash\n",
      "\tcrypto_dash\n",
      "\tcrypto_dogecoin\n",
      "\tcrypto_ethereum\n",
      "\tcrypto_ethereum_classic\n",
      "\tcrypto_litecoin\n",
      "\tcrypto_zcash\n",
      "\teclipse_megamovie\n",
      "\tepa_historical_air_quality\n",
      "\tethereum_blockchain\n",
      "\tfaa\n",
      "\tfcc_political_ads\n",
      "\tfda_drug\n",
      "\tfda_food\n",
      "\tfdic_banks\n",
      "\tfec\n",
      "\tfhir_synthea\n",
      "\tgenomics_cannabis\n",
      "\tgenomics_rice\n",
      "\tgeo_census_blockgroups\n",
      "\tgeo_census_tracts\n",
      "\tgeo_international_ports\n",
      "\tgeo_openstreetmap\n",
      "\tgeo_us_boundaries\n",
      "\tgeo_us_census_places\n",
      "\tgeo_us_roads\n",
      "\tgeo_whos_on_first\n",
      "\tgeolite2\n",
      "\tghcn_d\n",
      "\tghcn_m\n",
      "\tgithub_repos\n",
      "\tgoogle_analytics_sample\n",
      "\tgoogle_political_ads\n",
      "\thacker_news\n",
      "\thuman_genome_variants\n",
      "\thuman_variant_annotation\n",
      "\tiowa_liquor_sales\n",
      "\tirs_990\n",
      "\tlabeled_patents\n",
      "\tlibraries_io\n",
      "\tlondon_bicycles\n",
      "\tlondon_crime\n",
      "\tlondon_fire_brigade\n",
      "\tmedicare\n",
      "\tml_datasets\n",
      "\tmoon_phases\n",
      "\tnasa_wildfire\n",
      "\tncaa_basketball\n",
      "\tnew_york\n",
      "\tnew_york_311\n",
      "\tnew_york_citibike\n",
      "\tnew_york_mv_collisions\n",
      "\tnew_york_subway\n",
      "\tnew_york_taxi_trips\n",
      "\tnew_york_trees\n",
      "\tnhtsa_traffic_fatalities\n",
      "\tnlm_rxnorm\n",
      "\tnoaa_goes16\n",
      "\tnoaa_goes17\n",
      "\tnoaa_gsod\n",
      "\tnoaa_historic_severe_storms\n",
      "\tnoaa_hurricanes\n",
      "\tnoaa_icoads\n",
      "\tnoaa_lightning\n",
      "\tnoaa_passive_acoustic_index\n",
      "\tnoaa_pifsc_metadata\n",
      "\tnoaa_preliminary_severe_storms\n",
      "\tnoaa_significant_earthquakes\n",
      "\tnoaa_tsunami\n",
      "\tnppes\n",
      "\topen_images\n",
      "\topenaq\n",
      "\tpersistent_udfs\n",
      "\tsamples\n",
      "\tsan_francisco\n",
      "\tsan_francisco_311\n",
      "\tsan_francisco_bikeshare\n",
      "\tsan_francisco_film_locations\n",
      "\tsan_francisco_sffd_service_calls\n",
      "\tsan_francisco_sfpd_incidents\n",
      "\tsan_francisco_transit_muni\n",
      "\tsan_francisco_trees\n",
      "\tsdoh_bea_cainc30\n",
      "\tsdoh_cdc_wonder_natality\n",
      "\tsdoh_cms_dual_eligible_enrollment\n",
      "\tsdoh_hrsa_shortage_areas\n",
      "\tsdoh_hud_housing\n",
      "\tsdoh_hud_pit_homelessness\n",
      "\tsdoh_snap_enrollment\n",
      "\tsec_quarterly_financials\n",
      "\tstackoverflow\n",
      "\tsunroof_solar\n",
      "\tthe_met\n",
      "\tumiami_lincs\n",
      "\tun_sdg\n",
      "\tusa_names\n",
      "\tusda_nass_agriculture\n",
      "\tusfs_fia\n",
      "\tutility_eu\n",
      "\tutility_us\n",
      "\twikipedia\n",
      "\twise_all_sky_data_release\n",
      "\tworld_bank_global_population\n",
      "\tworld_bank_health_population\n",
      "\tworld_bank_intl_debt\n",
      "\tworld_bank_intl_education\n",
      "\tworld_bank_wdi\n",
      "\tworldpop\n"
     ]
    }
   ],
   "source": [
    "# list datasets in the default project:\n",
    "flag = printDatasetList(client)  #: assigning to `flag` suppresses printing the return value (normally `True`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "81uawTW5LFZo"
   },
   "source": [
    "This list should correspond to what is shown here https://bigquery.cloud.google.com/publicdatasets under the **bigquery-public-data** item:\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bEAfjVxOLFZo"
   },
   "source": [
    "Here is how to create a dataset reference object by assigning a project and a dataset name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZrSaLIkWLFZo"
   },
   "outputs": [],
   "source": [
    "dataset_id = 'samples' # 'samples' is one of the datasets listed above\n",
    "dataset_ref = client.dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5BlLbSA7LFZp"
   },
   "source": [
    "If our current project was something other than `bigquery-public-data`, we could still create this reference by specifying the project that contains the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NJK5yM9BLFZq"
   },
   "outputs": [],
   "source": [
    "dataset_id = 'samples'\n",
    "dataset_ref = client.dataset(dataset_id, project = 'bigquery-public-data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6_fYqMyGLFZr"
   },
   "source": [
    "How can we get the path of the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "otqzZohpLFZs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/projects/bigquery-public-data/datasets/samples'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checks to see where the path is, BigQuery or your own private db\n",
    "dataset_ref.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dRzK-hTuLFZt"
   },
   "source": [
    "Explore more of this object's members:\n",
    "\n",
    "*(HINT: Jupyter Notebooks does not support code completion, but Spyder and other Python IDEs do. If you copy all the above code to a Python file within the IDE, you can type `dataset_ref.` in a new line, then hit the [Tab] key to see the available members for the object.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s9HM7PiMLFZt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'samples'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#?\n",
    "dataset_ref.dataset_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NZB6yeerLFZu"
   },
   "source": [
    "Here is a function for listing the tables in a dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_E5S-MhtLFZu"
   },
   "outputs": [],
   "source": [
    "# function for listing tables in a dataset:\n",
    "def printTableList(client, dataset_id):\n",
    "    project = client.project\n",
    "    dataset_ref = client.dataset(dataset_id, project = project)    \n",
    "    tables = list(client.list_tables(dataset_ref)) # List of tables within dataset tables\n",
    "    if tables:\n",
    "        print('Tables in dataset {}:'.format(dataset_id))\n",
    "        for table in tables: \n",
    "            print('\\t{}'.format(table.table_id))\n",
    "        found = True\n",
    "    else:\n",
    "        print('{} dataset does not contain any tables.'.format(dataset_id))\n",
    "        found = False\n",
    "    return found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ksp2VbNcLFZv"
   },
   "source": [
    "Use this function to list the tables in the current dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F2KEisFzLFZv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in dataset samples:\n",
      "\tgithub_nested\n",
      "\tgithub_timeline\n",
      "\tgsod\n",
      "\tnatality\n",
      "\tshakespeare\n",
      "\ttrigrams\n",
      "\twikipedia\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the BigQuery UI first to understand where/what to query\n",
    "printTableList(client, dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XoZPwFx1LFZx"
   },
   "source": [
    "To create a reference to a table within the dataset, we use the `table_id` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rYXUHik0LFZx"
   },
   "outputs": [],
   "source": [
    "table_id = 'shakespeare'\n",
    "table_ref = dataset_ref.table(table_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3MZOaAuiLFZy"
   },
   "source": [
    "Check the name of the table that `table_ref` now points to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6B9AAg4tLFZz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shakespeare'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#?\n",
    "table_ref.table_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gOo7O5lVLFZ0"
   },
   "source": [
    "To access the data in the table itself, we use the `get_table()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rjnXTIoULFZ0"
   },
   "outputs": [],
   "source": [
    "table = client.get_table(table_ref)  # API Request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ggy5pIrYLFZ2"
   },
   "source": [
    "NOTE: The contents of the table are not actually in our memory after this call! We are working with a Big Data platform, now, and we could easily end up pulling GBs or TBs of data by accident. \n",
    "\n",
    "To minimise data bandwidth, memory consumption, and processing time, Big Data platforms employ ***lazy evaluation***. This means that no computation or data transfer actually takes place until we *realise* (use) the data. Even if we execute subsequent code that performs calculations on the data, no data flow or computation actually occurs until we request output (e.g. by executing a print to stdout or writing to a file). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Sa9uV6tLFZ2"
   },
   "source": [
    "What kind of object is returned by `client.get_table`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cdmNEp6ZLFZ3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "google.cloud.bigquery.table.Table"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#?\n",
    "type(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rcaJMPCNLFZ4"
   },
   "source": [
    "How can we view the design of the table (cOlumn names and types? The name of the boject attribute we need is the same term we learned in the module on databases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gt4FQZ88LFZ4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SchemaField('word', 'STRING', 'REQUIRED', 'A single unique word (where whitespace is the delimiter) extracted from a corpus.', ()), SchemaField('word_count', 'INTEGER', 'REQUIRED', 'The number of times this word appears in this corpus.', ()), SchemaField('corpus', 'STRING', 'REQUIRED', 'The work from which this word was extracted.', ()), SchemaField('corpus_date', 'INTEGER', 'REQUIRED', 'The year in which this corpus was published.', ())]\n"
     ]
    }
   ],
   "source": [
    "#?\n",
    "print(table.schema) # Directly gives us all the info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FfaKrQRSLFZ6"
   },
   "source": [
    "Again, this is messy. If we wanted to refer to the column names and types in code, we might use something like this (which we could then parse into a dict):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8187Fu57LFZ6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word STRING', 'word_count INTEGER', 'corpus STRING', 'corpus_date INTEGER']\n"
     ]
    }
   ],
   "source": [
    "result = [\"{0} {1}\".format(schema.name,schema.field_type) for schema in table.schema] # This is a list comprehension\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word STRING', 'word_count INTEGER', 'corpus STRING', 'corpus_date INTEGER']\n"
     ]
    }
   ],
   "source": [
    "# Same as list comprehension\n",
    "# Loop to print the schema name and schema type for the table 'shakespeare'\n",
    "result = []\n",
    "for field in table.schema:\n",
    "    #print(field.name,field.field_type)\n",
    "    result.append(field.name+\" \"+field.field_type)    \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZQz7xhfwLFZ7"
   },
   "source": [
    "But if we just want to print them, here is another neat function for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_LqvAXo3LFZ7"
   },
   "outputs": [],
   "source": [
    "# function to print a table schema:\n",
    "def printTableSchema(aTable):\n",
    "    schemas = list(aTable.schema)\n",
    "    if schemas:\n",
    "        print('Table schema for {}:'.format(aTable.table_id))\n",
    "        for aSchema in schemas:\n",
    "            print('\\t{0} {1}'.format(aSchema.name, aSchema.field_type))\n",
    "        found = True\n",
    "    else:\n",
    "        found = False\n",
    "    return found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SROTDIm8LFZ8"
   },
   "source": [
    "Use this function to print the table schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DpmWRmXmLFZ9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table schema for shakespeare:\n",
      "\tword STRING\n",
      "\tword_count INTEGER\n",
      "\tcorpus STRING\n",
      "\tcorpus_date INTEGER\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#?\n",
    "printTableSchema(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q1YugUUhLFZ-"
   },
   "source": [
    "Now that we know what the columns are, we can write queries. Actually, we construct a query job by assigning an SQL statement to a method of the `client` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-98-c9a9e4604bd6>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-98-c9a9e4604bd6>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    export GOOGLE_APPLICATION_CREDENTIALS=['/Users/allenj/Documents/Keys/Explorations-83ac1354c16d.json']\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "export GOOGLE_APPLICATION_CREDENTIALS=['/Users/allenj/Documents/Keys/Explorations-83ac1354c16d.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gq7cGALfLFZ-"
   },
   "outputs": [
    {
     "ename": "Forbidden",
     "evalue": "403 POST https://bigquery.googleapis.com/bigquery/v2/projects/bigquery-public-data/jobs: Access Denied: Project bigquery-public-data: User does not have bigquery.jobs.create permission in project bigquery-public-data.\n\n(job ID: af2de0f8-71ed-416a-bcfc-1d895f79ef99)\n\n                  -----Query Job SQL Follows-----                   \n\n    |    .    |    .    |    .    |    .    |    .    |    .    |\n   1:SELECT COUNT(1) FROM `bigquery-public-data.samples.shakespeare`\n    |    .    |    .    |    .    |    .    |    .    |    .    |",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-7b84bddb1973>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"SELECT COUNT(1) FROM `bigquery-public-data.samples.shakespeare`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mquery_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query, job_config, job_id, job_id_prefix, location, project, retry)\u001b[0m\n\u001b[1;32m   2142\u001b[0m         \u001b[0mjob_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_JobReference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2143\u001b[0m         \u001b[0mquery_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQueryJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2144\u001b[0;31m         \u001b[0mquery_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2146\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mquery_job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py\u001b[0m in \u001b[0;36m_begin\u001b[0;34m(self, client, retry)\u001b[0m\n\u001b[1;32m   3045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3047\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQueryJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3048\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGoogleCloudError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m             \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_for_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py\u001b[0m in \u001b[0;36m_begin\u001b[0;34m(self, client, retry)\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0;31m# job has an ID.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         api_response = client._call_api(\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_api_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m         )\n\u001b[1;32m    632\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36m_call_api\u001b[0;34m(self, retry, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEFAULT_RETRY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                 \u001b[0msleep_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m                 \u001b[0mon_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             )\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/google/cloud/_http.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexpect_json\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mForbidden\u001b[0m: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/bigquery-public-data/jobs: Access Denied: Project bigquery-public-data: User does not have bigquery.jobs.create permission in project bigquery-public-data.\n\n(job ID: af2de0f8-71ed-416a-bcfc-1d895f79ef99)\n\n                  -----Query Job SQL Follows-----                   \n\n    |    .    |    .    |    .    |    .    |    .    |    .    |\n   1:SELECT COUNT(1) FROM `bigquery-public-data.samples.shakespeare`\n    |    .    |    .    |    .    |    .    |    .    |    .    |"
     ]
    }
   ],
   "source": [
    "sql = \"SELECT COUNT(1) FROM `bigquery-public-data.samples.shakespeare`\"\n",
    "query_job = client.query(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DJVssU3mLFZ_"
   },
   "source": [
    "Why does this throw an error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4feq3JaqLFZ_"
   },
   "source": [
    "ANSWER: \n",
    "\n",
    "It's creating a job to which we don't have the ability to create a job, like a computer program. It takes the query and creates program on on Google Cloud and schedules it for execution. More complex than it seems to be. \n",
    "\n",
    "So, what can we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hCVH3AxrLFaA"
   },
   "outputs": [],
   "source": [
    "# No access to create data for that dataset. Connect to private project\n",
    "\n",
    "project_name = 'explorations-275222'\n",
    "client = bigquery.Client(project = project_name)\n",
    "\n",
    "sql = \"SELECT COUNT(1) FROM `bigquery-public-data.samples.shakespeare`\"\n",
    "query_job = client.query(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TTfuF8J0LFaA"
   },
   "source": [
    "If that worked, show what query_job is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZmiGhS0ALFaA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "google.cloud.bigquery.job.QueryJob"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#?\n",
    "type(query_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Src6_5auLFaB"
   },
   "source": [
    "Once again, due to lazy execution, no actual execution occurs until we request output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FCz4Yw9jLFaB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row((164656,), {'f0_': 0})\n"
     ]
    }
   ],
   "source": [
    "for row in query_job:  # API request - fetches results\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CQG3a1oALFaC"
   },
   "source": [
    "And, again, we need to manipulate this to make it neat. Each member of the rowset is a list and we only want to extract the value, which is in the first member:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qcq2F5vzLFaC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164656\n"
     ]
    }
   ],
   "source": [
    "print(row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cPqWb1_YLFaD"
   },
   "source": [
    "So, we now know that this table has 164,656 rows. (We would not want to print it!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6idZY0-3LFaD"
   },
   "source": [
    "A better coding practice is to write SQL statements that assign names (aliases) to derived values, so we don't forget what the resulting rowset contains. Rewite the above SQL statement so that the value returned is aliased a \"num_rows\", and assign the QueryJob as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NeHVJAm5LFaD"
   },
   "outputs": [],
   "source": [
    "#?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XUFlZ66lLFaE"
   },
   "source": [
    "Now we could use Python's `assert` statement to build a test into the first code block that operates on the rowset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6MHaNZh0LFaE"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "no row field 'num_rows'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-da61134388a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquery_job\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# API request - fetches results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Row values can be accessed by field name or index:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_rows\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_rows'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m#: for debugging bad sql\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/table.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1243\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xxx_field_to_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no row field {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xxx_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: no row field 'num_rows'"
     ]
    }
   ],
   "source": [
    "for row in query_job:  # API request - fetches results\n",
    "    # Row values can be accessed by field name or index:\n",
    "    assert row[0] == row.num_rows == row['num_rows']  #: for debugging bad sql\n",
    "    print(row.num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fP4GpU02LFaF"
   },
   "source": [
    "The above code checks that the name attribute of the value in `row[0]` is what we expected (i.e. \"num_rows\"). Also, it shows that we can refer to a field in a row by its object member `num_rows` or by using the same notation we use for Python dictionaries, `['num_rows']`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y83gunLZLFaF"
   },
   "source": [
    "Write, execute, and print the results of a query that fetches 10 rows from the table, each containing the \"word\", \"word_count\", and \"corpus\" fields: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xhvBwHzpLFaG"
   },
   "outputs": [],
   "source": [
    "#?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OlGpm9dmLFaH"
   },
   "source": [
    "(NOTE: Using `assert` religiously is good practice and will make debugging easier, but is probably overkill for non-production code.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "md6tWVvHLFaH"
   },
   "source": [
    "Whenever you catch yourself writing a swag of code to do something that seems rudimentary or low-level, there is a very good chance that you don't need to. A much easier way to handle the above requirement is to use the `to_dataframe` method of the QueryJob object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "19bjagBHLFaH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      f0_\n",
      "0  164656\n"
     ]
    }
   ],
   "source": [
    "df = query_job.to_dataframe()\n",
    "print(df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>164656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      f0_\n",
       "0  164656"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qc7vdIfALFaJ"
   },
   "source": [
    "Although the above doesn't use `assert` (which you might still want to include in some test code), you will be able to tell at a glance if something is wrong with the contents of the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DsWSuO95LFaJ"
   },
   "source": [
    "#### Final Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4mKynMuNLFaJ"
   },
   "source": [
    "1. Here is a readable way to code long SQL statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8nm7i1-rLFaJ"
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "    SELECT word, word_count, corpus \n",
    "    FROM `bigquery-public-data.samples.shakespeare` \n",
    "    LIMIT 10\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1j2w1aovLFaK"
   },
   "source": [
    "2. If you had an application that needed to modify the tables or datasets in the `bigquery-public-data` is project, you could copy them to our own project, where you would have the permissions to do as you please with the data (subject to Google's terms of use)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mOAZyGTcLFaL"
   },
   "source": [
    "3. We aren't limited to the datasets that are already in BigQuery. We can upload tables from our computer, and we can pull data in from other online souces. We will cover these tasks in another module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PJmK2n7vLFaL"
   },
   "source": [
    "#### Next Steps\n",
    "\n",
    "If you wish to pick up a few more skills you can go to https://cloud.google.com/bigquery/create-simple-app-api. (Note that we have already been through the preliminaries, so you can start at \"Download the sample code\".)\n",
    "\n",
    "Alternatively, you can take a deeper dive into the API here: https://googlecloudplatform.github.io/google-cloud-python/latest/bigquery/usage.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OFNsekmxLFaM"
   },
   "source": [
    "## - END -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KBAJLLeXLHs8"
   },
   "source": [
    ">\n",
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V1AVU7q-LIuO"
   },
   "source": [
    ">\n",
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fpehj_5ELJk9"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > >  2019 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "DsWSuO95LFaJ",
    "PJmK2n7vLFaL"
   ],
   "name": "DSIA Lab 2.2.4 .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
